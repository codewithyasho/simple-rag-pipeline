{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da3a735",
   "metadata": {},
   "source": [
    "## 1.Data ingestion pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f7eb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yasho\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from langchain_classic.document_loaders import PyMuPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99e69b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all the pdfs inside the directory\n",
    "def process_all_pdfs(directory):\n",
    "    '''Process all pdfs in a directory using PyMuPDF'''\n",
    "\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(directory)\n",
    "\n",
    "    # finding all pdfs recursively\n",
    "    pdf_files = list(pdf_dir.glob('**/*.pdf'))\n",
    "\n",
    "    print(f\"\\n====== Found {len(pdf_files)} PDF files to process ======\")\n",
    "\n",
    "    for file in pdf_files:\n",
    "        print(f\"\\n[INFO] Processing: {file.name} file\")\n",
    "\n",
    "        try:\n",
    "            loader = PyMuPDFLoader(\n",
    "                str(file)\n",
    "            )\n",
    "            documents = loader.load()\n",
    "\n",
    "            # .extend() adds individual items to the list\n",
    "            all_documents.extend(documents)\n",
    "\n",
    "            print(\n",
    "                f\"\\n✅ Successfully Loaded <{len(documents)}> pages from {file.name}\")\n",
    "            print(\"=\" * 50)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {file.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\n\\n[INFO] Total documents loaded: <{len(all_documents)}>\\n\")\n",
    "    return all_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "042bd371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Found 6 PDF files to process ======\n",
      "\n",
      "[INFO] Processing: Deep Learning 101.pdf file\n",
      "\n",
      "✅ Successfully Loaded <266> pages from Deep Learning 101.pdf\n",
      "==================================================\n",
      "\n",
      "[INFO] Processing: DeepSeek_OCR_paper.pdf file\n",
      "\n",
      "✅ Successfully Loaded <22> pages from DeepSeek_OCR_paper.pdf\n",
      "==================================================\n",
      "\n",
      "[INFO] Processing: mathematics-ML.pdf file\n",
      "\n",
      "✅ Successfully Loaded <266> pages from mathematics-ML.pdf\n",
      "==================================================\n",
      "\n",
      "[INFO] Processing: ML.pdf file\n",
      "\n",
      "✅ Successfully Loaded <169> pages from ML.pdf\n",
      "==================================================\n",
      "\n",
      "[INFO] Processing: pp_report_1.pdf file\n",
      "\n",
      "✅ Successfully Loaded <14> pages from pp_report_1.pdf\n",
      "==================================================\n",
      "\n",
      "[INFO] Processing: PP_REPORT_2.pdf file\n",
      "\n",
      "✅ Successfully Loaded <9> pages from PP_REPORT_2.pdf\n",
      "==================================================\n",
      "\n",
      "\n",
      "[INFO] Total documents loaded: <746>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_pdf_docs = process_all_pdfs(\"data/pdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c206ff71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'xdvipdfmx (20250205); modified using OpenPDF UNKNOWN', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-10-15T19:40:49+11:00', 'source': 'data\\\\pdfs\\\\Deep Learning 101.pdf', 'file_path': 'data\\\\pdfs\\\\Deep Learning 101.pdf', 'total_pages': 266, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-15T22:07:21+05:30', 'trapped': '', 'modDate': \"D:20251015220721+05'30'\", 'creationDate': \"D:20251015194049+11'00'\", 'page': 0}, page_content='')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a02aae1",
   "metadata": {},
   "source": [
    "## 2.splitting documents into chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e8d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b9824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_docs(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "\n",
    "    chunked_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "    print(\"\\n✅Document Splitted successfully!\")\n",
    "    print(\n",
    "        f\"\\nSplitted <{len(documents)}> documents into <{len(chunked_documents)}> chunks.\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    return chunked_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bbd46ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅Document Splitted successfully!\n",
      "\n",
      "Splitted <746> documents into <1445> chunks.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "chunks = split_docs(all_pdf_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a299515",
   "metadata": {},
   "source": [
    "## 3.creating new vectorstore from scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cefda7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_classic.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91a17212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_and_store(chunks):\n",
    "\n",
    "    try:\n",
    "        print(\"\\n[INFO] Embedding Initializing...\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        embedding_model = HuggingFaceEmbeddings(\n",
    "            model_name=\"BAAI/bge-small-en-v1.5\", show_progress=True,\n",
    "            model_kwargs={\n",
    "                'device': 'cpu'\n",
    "            },\n",
    "            encode_kwargs={\n",
    "                'batch_size': 32,\n",
    "                'normalize_embeddings': True\n",
    "            }\n",
    "\n",
    "        )\n",
    "\n",
    "        print(\"\\n[INFO] VectorStore Initializing...\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # Creates a new FAISS index from scratch\n",
    "        vectorstore = FAISS.from_documents(\n",
    "            documents=chunks,\n",
    "            embedding=embedding_model,\n",
    "            distance_strategy='COSINE'  # Better for normalized embeddings\n",
    "        )\n",
    "\n",
    "        print(f\"\\n[INFO] Vector dimension: {vectorstore.index.d}\")\n",
    "\n",
    "        print(\n",
    "            f\"[INFO] Total Vectors in the store: <{vectorstore.index.ntotal}>\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # Save\n",
    "        vectorstore.save_local(\"faiss_index\")\n",
    "        print(\"\\n✅✅ Successfully saved FAISS index locally\")\n",
    "\n",
    "        return vectorstore\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during embedding and storing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9de3c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore = embed_and_store(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b350f02",
   "metadata": {},
   "source": [
    "## 3.1 if vector store exists, directly load it from directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "448ea906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the vectorstore from disk\n",
    "def embed_and_load(embedding_model, vectorstore_path):\n",
    "    try:\n",
    "        print(\"\\n[INFO] Embedding Initializing...\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=embedding_model, show_progress=True,\n",
    "            model_kwargs={\n",
    "                'device': 'cpu'\n",
    "            },\n",
    "            encode_kwargs={\n",
    "                'batch_size': 32,\n",
    "                'normalize_embeddings': True\n",
    "            }\n",
    "\n",
    "        )\n",
    "\n",
    "        print(\"\\n[INFO] VectorStore Initializing...\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # loading existing vectorstore\n",
    "        vectorstore = FAISS.load_local(\n",
    "            vectorstore_path,\n",
    "            embeddings=embeddings,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "\n",
    "        print(f\"\\n[INFO] Vector dimension: {vectorstore.index.d}\")\n",
    "\n",
    "        print(\n",
    "            f\"[INFO] Total Vectors in the store: <{vectorstore.index.ntotal}>\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        print(\"\\n✅✅ Successfully LOADED Embeddings and Vectorstore.\")\n",
    "\n",
    "        return vectorstore\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during LOADING: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5450f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore = embed_and_load(embedding_model=\"BAAI/bge-small-en-v1.5\", vectorstore_path=\"faiss_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5517c",
   "metadata": {},
   "source": [
    "## 3.2 if vectorstore exist and want to add more documents, load existing vectorstore and add more docs/ new chunks to it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16ba21c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading existing vectorstore and adding more documents/ new chunks\n",
    "def load_and_add_new_docs(embedding_model, vectorstore_path, new_chunks):\n",
    "    try:\n",
    "        print(\"\\n[INFO] Embedding Initializing...\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=embedding_model, show_progress=True,\n",
    "            model_kwargs={\n",
    "                'device': 'cpu'\n",
    "            },\n",
    "            encode_kwargs={\n",
    "                'batch_size': 32,\n",
    "                'normalize_embeddings': True\n",
    "            }\n",
    "\n",
    "        )\n",
    "\n",
    "        print(\"\\n[INFO] VectorStore Initializing...\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # loading existing vectorstore\n",
    "        vectorstore = FAISS.load_local(\n",
    "            vectorstore_path,\n",
    "            embeddings=embeddings,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "\n",
    "        print(\"\\n[INFO] Adding new CHUNKS to the Vectorstore...\")\n",
    "\n",
    "        # adding new documents/ chunks to existing vectorstore\n",
    "        vectorstore.add_documents(new_chunks)\n",
    "\n",
    "       \n",
    "\n",
    "        print(f\"\\n[INFO] Vector dimension: {vectorstore.index.d}\")\n",
    "\n",
    "        print(\n",
    "            f\"[INFO] Total Vectors in the store: <{vectorstore.index.ntotal}>\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        print(\"\\n✅✅ Successfully ADDED new chunks to the Vectorstore.\")\n",
    "\n",
    "        return vectorstore\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during LOADING and ADDING: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9451e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore = load_and_add_new_docs(\n",
    "#     embedding_model=\"BAAI/bge-small-en-v1.5\", \n",
    "#     vectorstore_path=\"faiss_index\", \n",
    "#     new_chunks=chunks\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b30674",
   "metadata": {},
   "source": [
    "##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddb8292",
   "metadata": {},
   "source": [
    "## 4. create RAG pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "389d025e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_classic.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12c2f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_rag(query, vectorstore):\n",
    "    # Retrieve similar documents\n",
    "    similar_docs = vectorstore.similarity_search(\n",
    "        query=query,\n",
    "        k=3\n",
    "    )\n",
    "\n",
    "    # Initialize the Google Generative AI chat model\n",
    "    chat_model = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-pro\"\n",
    "    )\n",
    "\n",
    "    # Create a prompt by combining the query with the content of similar documents\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in similar_docs])\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        '''\n",
    "    Using the following context to answer the question below. \n",
    "    If the context is insufficient, please say \"I don't know\".\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "\n",
    "    question: {query}\n",
    "    '''\n",
    "    )\n",
    "\n",
    "    prompt = prompt.format_prompt(\n",
    "        context=context,\n",
    "        query=query\n",
    "    )\n",
    "\n",
    "    # Generate a response using the chat model\n",
    "    response = chat_model.invoke(prompt)\n",
    "\n",
    "    # print(context)\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbf8b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is llm fine-tuning?\"\n",
    "# rag_response = simple_rag(query, vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50d5e3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rag_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435ff25f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
